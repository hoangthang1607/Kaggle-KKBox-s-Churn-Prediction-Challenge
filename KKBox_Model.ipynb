{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "np.random.seed(167)\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #elif 'datetime' not in col_type.name:\n",
    "        #    df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno_train = train['msno'].tolist()\n",
    "msno_test = test['msno'].tolist()\n",
    "msno_all = list(set(msno_train).union(set(msno_test)))\n",
    "msno_inter = list(set(msno_train).intersection(set(msno_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. `user_logs` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_preprocess(df):\n",
    "    df = df.loc[df['msno'].isin(msno_all)]\n",
    "    df = reduce_mem_usage(df)\n",
    "    df = df.groupby('msno').agg({'msno': 'count',\n",
    "                                 'date': 'min',\n",
    "                                 'num_25': 'sum',\n",
    "                                 'num_50': 'sum',\n",
    "                                 'num_75': 'sum',\n",
    "                                 'num_985': 'sum',\n",
    "                                 'num_100': 'sum',\n",
    "                                 'num_unq': 'sum', \n",
    "                                 'total_secs': 'sum'})\n",
    "    df = df.rename(columns = {'msno': 'count'}).reset_index()  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "10it [23:01, 133.92s/it]\n"
     ]
    }
   ],
   "source": [
    "reader = pd.read_csv('user_logs.csv', chunksize=40000000)\n",
    "user_data = pd.DataFrame()\n",
    "for chunk in tqdm(reader):\n",
    "    chunk = user_preprocess(chunk)\n",
    "    user_data = pd.concat([user_data, chunk])\n",
    "del chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "user_logs = pd.read_csv('user_logs_v2.csv')\n",
    "user_logs = user_preprocess(user_logs)\n",
    "user_data = pd.concat([user_data, user_logs])\n",
    "del user_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_data.groupby('msno').agg({'count': 'sum',\n",
    "                                           'date': 'min',\n",
    "                                           'num_25': 'sum',\n",
    "                                           'num_50': 'sum',\n",
    "                                           'num_75': 'sum',\n",
    "                                           'num_985': 'sum',\n",
    "                                           'num_100': 'sum',\n",
    "                                           'num_unq': 'sum', \n",
    "                                           'total_secs': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_data.reset_index()\n",
    "user_data['date'] = pd.to_datetime(user_data['date'], format='%Y%m%d')\n",
    "user_data['year_start'] = user_data['date'].dt.year\n",
    "user_data = user_data.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs']\n",
    "for col in cols:\n",
    "    user_data[col] = user_data[col]/user_data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, user_data, on = 'msno', how = 'left')\n",
    "test = pd.merge(test, user_data, on = 'msno', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. `members_v3.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv('members_v3.csv')\n",
    "members = members.loc[members['msno'].isin(msno_all)] \n",
    "train = pd.merge(train, members, how = 'left', on = 'msno')\n",
    "test = pd.merge(test, members, how = 'left', on = 'msno')\n",
    "del members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def members_preprocess(df):\n",
    "    df['city'] = df['city'].fillna(0)\n",
    "    df['city'] = df['city'].apply(lambda x: 1 if ((x == 0) | (x == 1)) else 0)\n",
    "    df['gender'] = df['gender'].fillna('unknown')\n",
    "    df['registered_via'] = df['registered_via'].fillna(0)\n",
    "    df['registered_via'] = df['registered_via'].apply(lambda x: 0 if ((x == 0) | (x == 7)) else (2 if x == 4 else 1))\n",
    "    df['registration_init_time'] = pd.to_datetime(df['registration_init_time'], format='%Y%m%d')\n",
    "    df['registration_year'] = df['registration_init_time'].dt.year\n",
    "    df = df.drop(['bd', 'registration_init_time'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = members_preprocess(train)\n",
    "test = members_preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. `transactions.csv` and `transactions_v2.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.concat([pd.read_csv('transactions.csv'), pd.read_csv('transactions_v2.csv')], axis = 0)\n",
    "transactions = reduce_mem_usage(transactions)\n",
    "transactions = transactions.loc[transactions['msno'].isin(msno_all)] \n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'], format='%Y%m%d')\n",
    "transactions['membership_expire_date'] = pd.to_datetime(transactions['membership_expire_date'], format='%Y%m%d')\n",
    "transactions = transactions.sort_values(by = ['msno', 'transaction_date'], ascending = [True, True])\n",
    "train_transactions = transactions.loc[transactions['msno'].isin(msno_train)]\n",
    "test_transactions = transactions.loc[transactions['msno'].isin(msno_test)]\n",
    "del transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_features(transactions, df, is_train = True):\n",
    "    check1 = transactions.groupby('msno')['transaction_date', 'membership_expire_date', 'is_cancel'].nth(-1)\n",
    "    if is_train == True:\n",
    "        check2 = transactions.loc[transactions['membership_expire_date'] <= pd.Timestamp('2017-03-31'), ['msno', 'transaction_date', 'membership_expire_date', 'is_cancel']]\n",
    "    else:\n",
    "        check2 = transactions.loc[transactions['membership_expire_date'] <= pd.Timestamp('2017-04-30'), ['msno', 'transaction_date', 'membership_expire_date', 'is_cancel']]\n",
    "    check3 = check2.groupby('msno')['membership_expire_date'].max()\n",
    "    check4 = check1.loc[check1['membership_expire_date'] != check3]\n",
    "    check5 = check1.loc[check1['membership_expire_date'] == check3]\n",
    "    case2 = check5.loc[check5['is_cancel'] == 0].index.tolist()\n",
    "    case3 = check4.loc[(check4['transaction_date'] < check3.loc[check4.index]) & (check4['is_cancel'] == 0)].index.tolist()\n",
    "    case4 = check4.loc[(check4['transaction_date'] >= check3.loc[check4.index]) & (check4['is_cancel'] == 0)].index.tolist()\n",
    "    del check1, check2, check3, check4, check5\n",
    "    df['transaction_proba'] = 0.85\n",
    "    df.loc[df['msno'].isin(case2), 'transaction_proba'] = 0.6\n",
    "    df.loc[df['msno'].isin(case3), 'transaction_proba'] = 0.25\n",
    "    df.loc[train['msno'].isin(case4), 'transaction_proba'] = 0.02\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transaction_features(train_transactions, train, is_train = True)\n",
    "test = transaction_features(test_transactions, test, is_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactions_preprocess(transactions, df):\n",
    "    transactions['membership_duration'] = ((transactions['membership_expire_date'] - transactions['transaction_date'])/np.timedelta64(1, 'D')).astype(int)\n",
    "    transactions.loc[transactions['membership_duration'] < 0, 'membership_duration'] = 0\n",
    "    transactions['discount'] = (transactions['plan_list_price'] - transactions['actual_amount_paid']).apply(lambda x: 1 if x > 0 else 0)\n",
    "    transactions['time_interrupt'] = transactions.groupby('msno')['transaction_date'].diff()/np.timedelta64(1, 'D')\n",
    "    sum_up = transactions.groupby('msno').agg({'payment_method_id': lambda x: x.mode().iloc[0], \n",
    "                                               'payment_plan_days': np.median,\n",
    "                                               'is_cancel': np.max,\n",
    "                                               'discount': np.max,\n",
    "                                               'actual_amount_paid': np.mean, \n",
    "                                               'membership_duration': lambda x: x.mode().iloc[0],\n",
    "                                               'time_interrupt': np.median,\n",
    "                                               'transaction_date': 'first'})\n",
    "    sum_up['time_interrupt'] = sum_up['time_interrupt'].fillna(0)\n",
    "    sum_up['payment_method_id'] = sum_up['payment_method_id'].apply(lambda x: 1 if x == 41 else 0)\n",
    "    sum_up['transaction_date'] = sum_up['transaction_date'].dt.year\n",
    "    df = pd.merge(df, sum_up.reset_index(), on = 'msno')\n",
    "    del transactions, sum_up\n",
    "    return reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transactions_preprocess(train_transactions, train)\n",
    "test = transactions_preprocess(test_transactions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_transactions, test_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['registration_year'].isnull(), 'registration_year'] = train.loc[train['registration_year'].isnull(), 'transaction_date']\n",
    "train.loc[train['year_start'].isnull(), 'year_start'] = train.loc[train['year_start'].isnull(), 'transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['registration_year'].isnull(), 'registration_year'] = test.loc[test['registration_year'].isnull(), 'transaction_date']\n",
    "test.loc[test['year_start'].isnull(), 'year_start'] = test.loc[test['year_start'].isnull(), 'transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(df):\n",
    "    nb_null = df.isnull().any(axis=1).sum()\n",
    "    idx = np.random.permutation(df.loc[~df.isnull().any(axis = 1)].index)[:nb_null]\n",
    "    df.loc[df.isnull().any(axis = 1)] = df.loc[idx].values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['count', 'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs']\n",
    "train.loc[:, cols] = imputer(train.loc[:, cols])\n",
    "test.loc[:, cols] = imputer(test.loc[:, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['count', 'year_start', 'registration_year', 'payment_plan_days', 'time_interrupt']\n",
    "train[cols] = train[cols].astype(int)\n",
    "test[cols] = test[cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>count</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>...</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>transaction_proba</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>discount</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>membership_duration</th>\n",
       "      <th>time_interrupt</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>8.640625</td>\n",
       "      <td>1.671875</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>31.734375</td>\n",
       "      <td>12.156250</td>\n",
       "      <td>7513.968262</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149.000</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1.837891</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.287598</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>10.101562</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>2712.790527</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.500</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>31.531250</td>\n",
       "      <td>2.283203</td>\n",
       "      <td>1.237305</td>\n",
       "      <td>1.231445</td>\n",
       "      <td>19.546875</td>\n",
       "      <td>44.718750</td>\n",
       "      <td>5648.679688</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.125</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.573242</td>\n",
       "      <td>0.786621</td>\n",
       "      <td>0.646973</td>\n",
       "      <td>10.765625</td>\n",
       "      <td>17.484375</td>\n",
       "      <td>3538.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>143.875</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "      <td>1.169922</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>0.439209</td>\n",
       "      <td>0.276855</td>\n",
       "      <td>14.953125</td>\n",
       "      <td>14.414062</td>\n",
       "      <td>3874.755615</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117.125</td>\n",
       "      <td>186</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  count     num_25  \\\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1     64   8.640625   \n",
       "1  f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=         1     80   1.837891   \n",
       "2  zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=         1    342  31.531250   \n",
       "3  8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=         1    136   5.093750   \n",
       "4  K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=         1    271   1.169922   \n",
       "\n",
       "     num_50    num_75   num_985    num_100    num_unq   total_secs  \\\n",
       "0  1.671875  0.890625  1.437500  31.734375  12.156250  7513.968262   \n",
       "1  0.562500  0.287598  0.312500  10.101562   9.164062  2712.790527   \n",
       "2  2.283203  1.237305  1.231445  19.546875  44.718750  5648.679688   \n",
       "3  1.573242  0.786621  0.646973  10.765625  17.484375  3538.294922   \n",
       "4  0.715820  0.439209  0.276855  14.953125  14.414062  3874.755615   \n",
       "\n",
       "         ...         registration_year  transaction_proba payment_method_id  \\\n",
       "0        ...                      2013           0.600098                 0   \n",
       "1        ...                      2013           0.250000                 0   \n",
       "2        ...                      2013           0.020004                 0   \n",
       "3        ...                      2014           0.850098                 1   \n",
       "4        ...                      2014           0.020004                 1   \n",
       "\n",
       "   payment_plan_days  is_cancel  discount  actual_amount_paid  \\\n",
       "0                  0          1         0             149.000   \n",
       "1                 30          0         0             134.500   \n",
       "2                 30          0         0             149.125   \n",
       "3                 30          1         0             143.875   \n",
       "4                 30          1         0             117.125   \n",
       "\n",
       "   membership_duration  time_interrupt  transaction_date  \n",
       "0                   30              31              2015  \n",
       "1                   30              34              2016  \n",
       "2                   30              32              2015  \n",
       "3                    0               8              2015  \n",
       "4                  186              30              2015  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>count</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>...</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>transaction_proba</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>discount</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>membership_duration</th>\n",
       "      <th>time_interrupt</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.079830e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=</td>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>21.703125</td>\n",
       "      <td>4.398438</td>\n",
       "      <td>3.111328</td>\n",
       "      <td>3.269531</td>\n",
       "      <td>47.718750</td>\n",
       "      <td>68.812500</td>\n",
       "      <td>-1.131702e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5.089844</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>16.968750</td>\n",
       "      <td>17.421875</td>\n",
       "      <td>4.419593e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>9.765625</td>\n",
       "      <td>1.410156</td>\n",
       "      <td>0.834473</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>11.015625</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>3.233542e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.625000</td>\n",
       "      <td>5.941232e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  count     num_25  \\\n",
       "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=         0      4   2.000000   \n",
       "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0    815  21.703125   \n",
       "2  rFC9eSG/tMuzpre6cwcMLZHEYM89xY02qcz7HL4//jc=         0     77   5.089844   \n",
       "3  WZ59dLyrQcE7ft06MZ5dj40BnlYQY7PHgg/54+HaCSE=         0    139   9.765625   \n",
       "4  aky/Iv8hMp1/V/yQHLtaVuEmmAxkB5GuasQZePJ7NU4=         0     16   0.750000   \n",
       "\n",
       "     num_50    num_75   num_985    num_100    num_unq    total_secs  \\\n",
       "0  0.500000  0.250000  0.000000   0.250000   3.000000  2.079830e+02   \n",
       "1  4.398438  3.111328  3.269531  47.718750  68.812500 -1.131702e+13   \n",
       "2  1.103516  0.519531  0.480469  16.968750  17.421875  4.419593e+03   \n",
       "3  1.410156  0.834473  0.726562  11.015625  17.875000  3.233542e+03   \n",
       "4  0.437500  0.250000  0.187500  23.000000  23.625000  5.941232e+03   \n",
       "\n",
       "         ...         registration_year  transaction_proba payment_method_id  \\\n",
       "0        ...                      2015           0.600098                 1   \n",
       "1        ...                      2005           0.600098                 0   \n",
       "2        ...                      2014           0.600098                 1   \n",
       "3        ...                      2015           0.600098                 1   \n",
       "4        ...                      2016           0.600098                 0   \n",
       "\n",
       "   payment_plan_days  is_cancel  discount  actual_amount_paid  \\\n",
       "0                 30          0         0                99.0   \n",
       "1                 30          0         0               149.0   \n",
       "2                 30          1         1                91.0   \n",
       "3                 30          0         0                99.0   \n",
       "4                 30          0         0               129.0   \n",
       "\n",
       "   membership_duration  time_interrupt  transaction_date  \n",
       "0                   31              31              2015  \n",
       "1                   31              31              2015  \n",
       "2                   31              30              2015  \n",
       "3                   31              31              2015  \n",
       "4                   30              31              2016  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dummies = ['city', 'gender', 'registered_via', 'payment_method_id', 'is_cancel', 'discount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[cols_dummies].astype(str))\n",
    "test_dummies = pd.get_dummies(test[cols_dummies].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_dummies, axis = 1)\n",
    "test = test.drop(cols_dummies, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float16, float32 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train.iloc[:, 2:])\n",
    "train.iloc[:, 2:] = scaler.transform(train.iloc[:, 2:])\n",
    "test.iloc[:, 2:] = scaler.transform(test.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_processed.csv')\n",
    "test = pd.read_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>count</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_unknown</th>\n",
       "      <th>registered_via_0</th>\n",
       "      <th>registered_via_1</th>\n",
       "      <th>registered_via_2</th>\n",
       "      <th>payment_method_id_0</th>\n",
       "      <th>payment_method_id_1</th>\n",
       "      <th>is_cancel_0</th>\n",
       "      <th>is_cancel_1</th>\n",
       "      <th>discount_0</th>\n",
       "      <th>discount_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076843</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415771</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.029327</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.016159</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329346</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn     count    num_25  \\\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1  0.076843  0.005672   \n",
       "1  f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=         1  0.096313  0.001206   \n",
       "2  zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=         1  0.415771  0.020706   \n",
       "3  8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=         1  0.164673  0.003345   \n",
       "4  K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=         1  0.329346  0.000768   \n",
       "\n",
       "     num_50    num_75   num_985   num_100   num_unq  total_secs     ...      \\\n",
       "0  0.014168  0.010010  0.012222  0.047607  0.007957    0.973633     ...       \n",
       "1  0.004768  0.003231  0.002657  0.015160  0.005825    0.973633     ...       \n",
       "2  0.019348  0.013901  0.010468  0.029327  0.031189    0.973633     ...       \n",
       "3  0.013336  0.008835  0.005501  0.016159  0.011757    0.973633     ...       \n",
       "4  0.006065  0.004936  0.002354  0.022430  0.009567    0.973633     ...       \n",
       "\n",
       "   gender_unknown  registered_via_0  registered_via_1  registered_via_2  \\\n",
       "0               0                 0                 1                 0   \n",
       "1               0                 0                 1                 0   \n",
       "2               0                 0                 1                 0   \n",
       "3               1                 1                 0                 0   \n",
       "4               0                 1                 0                 0   \n",
       "\n",
       "   payment_method_id_0  payment_method_id_1  is_cancel_0  is_cancel_1  \\\n",
       "0                    1                    0            0            1   \n",
       "1                    1                    0            1            0   \n",
       "2                    1                    0            1            0   \n",
       "3                    0                    1            0            1   \n",
       "4                    0                    1            0            1   \n",
       "\n",
       "   discount_0  discount_1  \n",
       "0           1           0  \n",
       "1           1           0  \n",
       "2           1           0  \n",
       "3           1           0  \n",
       "4           1           0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 2:].values\n",
    "Y = train['is_churn'].values\n",
    "X_test = test.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.round(pd.read_csv('xgb2.csv')['is_churn']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 70000, random_state = 167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "params_C = [1, 10, 20, 50, 80, 100]\n",
    "res = []\n",
    "for c in params_C:\n",
    "    clf = LogisticRegression(C = c)\n",
    "    clf.fit(X, Y)\n",
    "    res.append(log_loss(Y_test, clf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 1)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 20, 50, 80, 100, 200, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C': [1, 10, 20, 50, 80, 100, 200, 500]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = params, cv = 5, scoring = 'neg_log_loss')\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 80}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1342809992858557"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "Y_test = clf.predict_proba(X_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test[:, 1].ravel()})\n",
    "submission.to_csv('logistic2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1200, num = 5)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [None, 5, 10],\n",
    "               'min_samples_leaf': [5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 60 is smaller than n_iter=100. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=167, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "clf_random.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_estimators = [150, 200, 300, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for c in params_estimators:\n",
    "    clf = RandomForestClassifier(n_estimators = c, max_depth = 6, min_samples_leaf = 10)\n",
    "    clf.fit(X, Y)\n",
    "    res.append(log_loss(Y_test, clf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, max_depth = 5, min_samples_leaf = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict_proba(X)\n",
    "Y_test_pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13323123420415175"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4310552316781389"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = clf.predict_proba(X_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test[:, 1].ravel()})\n",
    "submission.to_csv('randomforest5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C = 20, kernel = 'rbf', probability = True)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from catboost import cv\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(10):\n",
    "    my_random_seed = i*42 + 2013\n",
    "    model = CatBoostClassifier(iterations=300, learning_rate=0.1, random_seed=my_random_seed, loss_function='CrossEntropy', \n",
    "                               custom_loss = 'Logloss', l2_leaf_reg=3, bagging_temperature=1, random_strength=1, \n",
    "                               one_hot_max_size=2, leaf_estimation_method='Newton')\n",
    "    model.fit(X_train, Y_train, eval_set=(X_val, Y_val), verbose=False)\n",
    "    yhat_validation = model.predict_proba(X_val)\n",
    "    scores.append(log_loss(Y_val, yhat_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4623435\ttest: 0.7592488\tbest: 0.7592488 (0)\ttotal: 209ms\tremaining: 31.1s\n",
      "50:\tlearn: 0.0863036\ttest: 0.6393257\tbest: 0.6324097 (44)\ttotal: 10.2s\tremaining: 19.8s\n",
      "100:\tlearn: 0.0823179\ttest: 0.6202184\tbest: 0.6173974 (91)\ttotal: 20.3s\tremaining: 9.82s\n",
      "149:\tlearn: 0.0804320\ttest: 0.6283207\tbest: 0.6158412 (117)\ttotal: 30.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6158411544\n",
      "bestIteration = 117\n",
      "\n",
      "Shrink model to first 118 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d1476e9cf8>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=150, learning_rate=0.1, od_type='Iter', od_wait=50, loss_function='CrossEntropy', \n",
    "                        custom_loss = 'Logloss', random_seed = 167, l2_leaf_reg=3, bagging_temperature=1, random_strength=1, \n",
    "                        one_hot_max_size=2, leaf_estimation_method='Newton')\n",
    "cb.fit(X, Y, eval_set=(X_test, Y_test), verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cb.predict_proba(X)\n",
    "Y_test_pred = cb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08149388292380776"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6158411544438331"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = np.array(cb.get_feature_importance(Pool(X, Y)))\n",
    "idx = np.argsort(feature_importance)[-10:][::-1]\n",
    "X.columns[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict_proba(X_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test[:, 1].ravel()})\n",
    "submission.to_csv('cb3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators = 150,\n",
    " max_depth=5,\n",
    " min_child_weight=5,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.719519\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "[50]\tvalidation_0-logloss:0.506661\n",
      "[100]\tvalidation_0-logloss:0.484829\n",
      "[149]\tvalidation_0-logloss:0.479807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=5, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(X, Y, eval_metric = 'logloss', eval_set = [(X_test, Y_test)], early_stopping_rounds = 50, verbose = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': {'logloss': [0.719519,\n",
       "   0.716481,\n",
       "   0.727004,\n",
       "   0.750808,\n",
       "   0.69024,\n",
       "   0.67138,\n",
       "   0.654952,\n",
       "   0.635765,\n",
       "   0.623575,\n",
       "   0.647767,\n",
       "   0.672103,\n",
       "   0.674902,\n",
       "   0.634993,\n",
       "   0.624003,\n",
       "   0.618017,\n",
       "   0.615516,\n",
       "   0.6362,\n",
       "   0.639091,\n",
       "   0.652597,\n",
       "   0.653168,\n",
       "   0.672905,\n",
       "   0.639474,\n",
       "   0.640413,\n",
       "   0.65823,\n",
       "   0.645933,\n",
       "   0.641964,\n",
       "   0.647978,\n",
       "   0.647777,\n",
       "   0.636963,\n",
       "   0.650265,\n",
       "   0.653753,\n",
       "   0.642096,\n",
       "   0.654799,\n",
       "   0.656968,\n",
       "   0.651414,\n",
       "   0.651878,\n",
       "   0.628413,\n",
       "   0.620166,\n",
       "   0.61493,\n",
       "   0.618078,\n",
       "   0.619764,\n",
       "   0.612396,\n",
       "   0.59021,\n",
       "   0.571529,\n",
       "   0.553926,\n",
       "   0.537583,\n",
       "   0.537571,\n",
       "   0.521872,\n",
       "   0.520084,\n",
       "   0.519927,\n",
       "   0.506661,\n",
       "   0.509501,\n",
       "   0.508163,\n",
       "   0.496296,\n",
       "   0.496379,\n",
       "   0.49772,\n",
       "   0.497843,\n",
       "   0.497984,\n",
       "   0.499231,\n",
       "   0.500268,\n",
       "   0.48999,\n",
       "   0.488737,\n",
       "   0.490426,\n",
       "   0.514682,\n",
       "   0.513785,\n",
       "   0.503482,\n",
       "   0.508247,\n",
       "   0.508143,\n",
       "   0.506144,\n",
       "   0.507374,\n",
       "   0.506766,\n",
       "   0.507548,\n",
       "   0.50767,\n",
       "   0.505439,\n",
       "   0.503921,\n",
       "   0.503485,\n",
       "   0.501826,\n",
       "   0.501854,\n",
       "   0.501133,\n",
       "   0.501199,\n",
       "   0.501047,\n",
       "   0.500765,\n",
       "   0.499415,\n",
       "   0.499552,\n",
       "   0.498371,\n",
       "   0.493417,\n",
       "   0.493084,\n",
       "   0.491883,\n",
       "   0.491398,\n",
       "   0.490836,\n",
       "   0.491519,\n",
       "   0.492796,\n",
       "   0.490915,\n",
       "   0.489448,\n",
       "   0.487166,\n",
       "   0.486813,\n",
       "   0.486693,\n",
       "   0.485993,\n",
       "   0.488017,\n",
       "   0.485261,\n",
       "   0.484829,\n",
       "   0.484986,\n",
       "   0.488362,\n",
       "   0.486341,\n",
       "   0.486209,\n",
       "   0.486285,\n",
       "   0.4882,\n",
       "   0.48788,\n",
       "   0.487656,\n",
       "   0.486676,\n",
       "   0.486498,\n",
       "   0.486492,\n",
       "   0.485815,\n",
       "   0.485349,\n",
       "   0.485262,\n",
       "   0.484897,\n",
       "   0.485044,\n",
       "   0.485053,\n",
       "   0.485191,\n",
       "   0.484538,\n",
       "   0.483604,\n",
       "   0.482867,\n",
       "   0.48266,\n",
       "   0.482421,\n",
       "   0.481415,\n",
       "   0.48101,\n",
       "   0.480856,\n",
       "   0.479411,\n",
       "   0.483629,\n",
       "   0.479617,\n",
       "   0.479149,\n",
       "   0.479574,\n",
       "   0.479643,\n",
       "   0.479692,\n",
       "   0.479223,\n",
       "   0.479611,\n",
       "   0.479493,\n",
       "   0.481571,\n",
       "   0.481495,\n",
       "   0.482593,\n",
       "   0.482668,\n",
       "   0.482116,\n",
       "   0.478984,\n",
       "   0.479304,\n",
       "   0.479733,\n",
       "   0.47934,\n",
       "   0.480505,\n",
       "   0.479946,\n",
       "   0.480128,\n",
       "   0.479807]}}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = xgb1.predict_proba(X_train)\n",
    "Y_val_pred = xgb1.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06598820278000116"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y_train, Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06582322741244472"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y_val, Y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = xgb1.predict_proba(X_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test[:, 1].ravel()})\n",
    "submission.to_csv('xgb4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05197452, 0.03541401, 0.03210191, 0.02980892, 0.02598726,\n",
       "       0.03617834, 0.03490446, 0.00178344, 0.00738853, 0.02980892,\n",
       "       0.03847134, 0.04484076, 0.21426752, 0.14343949, 0.12050956,\n",
       "       0.02242038, 0.02012739, 0.00152866, 0.00229299, 0.00152866,\n",
       "       0.00509554, 0.00917197, 0.00203822, 0.00254777, 0.0155414 ,\n",
       "       0.00407643, 0.03796178, 0.00611465, 0.01936306, 0.0033121 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d14da7f198>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plot_importance(xgb1, max_num_features=10, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_shape = (30, )))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(80, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 970960 samples, validate on 907471 samples\n",
      "Epoch 1/10\n",
      " - 23s - loss: 0.1341 - acc: 0.9491 - val_loss: 0.6204 - val_acc: 0.7008\n",
      "Epoch 2/10\n",
      " - 23s - loss: 0.1158 - acc: 0.9550 - val_loss: 0.5857 - val_acc: 0.8044\n",
      "Epoch 3/10\n",
      " - 23s - loss: 0.1117 - acc: 0.9564 - val_loss: 0.6708 - val_acc: 0.6496\n",
      "Epoch 4/10\n",
      " - 23s - loss: 0.1101 - acc: 0.9569 - val_loss: 0.6561 - val_acc: 0.7084\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.1092 - acc: 0.9575 - val_loss: 0.5791 - val_acc: 0.7472\n",
      "Epoch 6/10\n",
      " - 23s - loss: 0.1083 - acc: 0.9576 - val_loss: 0.6773 - val_acc: 0.6626\n",
      "Epoch 7/10\n",
      " - 23s - loss: 0.1076 - acc: 0.9578 - val_loss: 0.6379 - val_acc: 0.6274\n",
      "Epoch 8/10\n",
      " - 23s - loss: 0.1070 - acc: 0.9579 - val_loss: 0.5466 - val_acc: 0.7758\n",
      "Epoch 9/10\n",
      " - 23s - loss: 0.1062 - acc: 0.9583 - val_loss: 0.5384 - val_acc: 0.7798\n",
      "Epoch 10/10\n",
      " - 23s - loss: 0.1056 - acc: 0.9584 - val_loss: 0.5712 - val_acc: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d081d57400>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size = 128, epochs = 10, validation_data = (X_test, Y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test.ravel()})\n",
    "submission.to_csv('nn3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def features_stacking(X, Y, X_test, model, cv = 4, name_model_as_feature = 'logistic', random_state = True):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle = True)\n",
    "    # Create an empty dictionary to keep k-fold\n",
    "    train_splits = {}\n",
    "    # Loop for k-fold index to generate X_train, X_val, Y_train, Y_val of each fold\n",
    "    for (i, (train_index, val_index)) in enumerate(skf.split(X, Y)):\n",
    "        train_splits['Fold_' + str(i + 1)] = (train_index, val_index, X[train_index], X[val_index], Y[train_index], Y[val_index])\n",
    "    # Create an empty DataFrame to keep features stacking of training data\n",
    "    stacking_train = pd.DataFrame(columns = [name_model_as_feature])\n",
    "    # Create an empty array to compute sum of probability of test data\n",
    "    sum_proba_test = np.zeros(X_test.shape[0])\n",
    "    # Loop for k_fold\n",
    "    for i in range(cv):\n",
    "        # Retrieve infomation of fold_i+1\n",
    "        (train_index, val_index, X_train, X_val, Y_train, Y_val) = train_splits['Fold_' + str(i + 1)]\n",
    "        # Set random_state for the model and fit\n",
    "        if random_state:\n",
    "            model.set_params(random_state = np.random.randint(2019))\n",
    "        model.fit(X_train, Y_train)\n",
    "        # Append results on X_val to stacking_train DataFrame\n",
    "        stacking_train = pd.concat([stacking_train, pd.DataFrame(model.predict_proba(X_val)[:, 1], columns = [name_model_as_feature], index = val_index)], axis = 0)\n",
    "        # Compute predict_proba of X_test\n",
    "        sum_proba_test += model.predict_proba(X_test)[:, 1]\n",
    "    # Reset index of stacking_train\n",
    "    stacking_train = stacking_train.sort_index()\n",
    "    # Create a DataFrame to keep stacking_test\n",
    "    stacking_test = pd.DataFrame(data = sum_proba_test/cv, columns = [name_model_as_feature])\n",
    "    return (stacking_train, stacking_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 5, min_samples_leaf = 10)\n",
    "randomforest = features_stacking(X, Y, X_test, model, cv = 4, name_model_as_feature = 'randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4692097\ttotal: 279ms\tremaining: 33.2s\n",
      "1:\tlearn: 0.3795942\ttotal: 521ms\tremaining: 30.8s\n",
      "2:\tlearn: 0.3135115\ttotal: 749ms\tremaining: 29.2s\n",
      "3:\tlearn: 0.2421535\ttotal: 993ms\tremaining: 28.8s\n",
      "4:\tlearn: 0.1853727\ttotal: 1.24s\tremaining: 28.6s\n",
      "5:\tlearn: 0.1643378\ttotal: 1.49s\tremaining: 28.2s\n",
      "6:\tlearn: 0.1444512\ttotal: 1.76s\tremaining: 28.4s\n",
      "7:\tlearn: 0.1314347\ttotal: 1.98s\tremaining: 27.7s\n",
      "8:\tlearn: 0.1253807\ttotal: 2.2s\tremaining: 27.2s\n",
      "9:\tlearn: 0.1174898\ttotal: 2.44s\tremaining: 26.8s\n",
      "10:\tlearn: 0.1115741\ttotal: 2.68s\tremaining: 26.6s\n",
      "11:\tlearn: 0.1074104\ttotal: 2.92s\tremaining: 26.3s\n",
      "12:\tlearn: 0.1058054\ttotal: 3.2s\tremaining: 26.3s\n",
      "13:\tlearn: 0.1031069\ttotal: 3.47s\tremaining: 26.2s\n",
      "14:\tlearn: 0.1016330\ttotal: 3.7s\tremaining: 25.9s\n",
      "15:\tlearn: 0.0993239\ttotal: 3.92s\tremaining: 25.5s\n",
      "16:\tlearn: 0.0984292\ttotal: 4.15s\tremaining: 25.1s\n",
      "17:\tlearn: 0.0974612\ttotal: 4.39s\tremaining: 24.9s\n",
      "18:\tlearn: 0.0969290\ttotal: 4.64s\tremaining: 24.7s\n",
      "19:\tlearn: 0.0959560\ttotal: 4.87s\tremaining: 24.3s\n",
      "20:\tlearn: 0.0949883\ttotal: 5.09s\tremaining: 24s\n",
      "21:\tlearn: 0.0941910\ttotal: 5.31s\tremaining: 23.7s\n",
      "22:\tlearn: 0.0936012\ttotal: 5.56s\tremaining: 23.4s\n",
      "23:\tlearn: 0.0931565\ttotal: 5.79s\tremaining: 23.2s\n",
      "24:\tlearn: 0.0927474\ttotal: 6.04s\tremaining: 22.9s\n",
      "25:\tlearn: 0.0922752\ttotal: 6.27s\tremaining: 22.7s\n",
      "26:\tlearn: 0.0917460\ttotal: 6.52s\tremaining: 22.4s\n",
      "27:\tlearn: 0.0912861\ttotal: 6.76s\tremaining: 22.2s\n",
      "28:\tlearn: 0.0908125\ttotal: 7s\tremaining: 22s\n",
      "29:\tlearn: 0.0904452\ttotal: 7.24s\tremaining: 21.7s\n",
      "30:\tlearn: 0.0902280\ttotal: 7.49s\tremaining: 21.5s\n",
      "31:\tlearn: 0.0900433\ttotal: 7.74s\tremaining: 21.3s\n",
      "32:\tlearn: 0.0897930\ttotal: 7.98s\tremaining: 21s\n",
      "33:\tlearn: 0.0895985\ttotal: 8.19s\tremaining: 20.7s\n",
      "34:\tlearn: 0.0893915\ttotal: 8.44s\tremaining: 20.5s\n",
      "35:\tlearn: 0.0890781\ttotal: 8.69s\tremaining: 20.3s\n",
      "36:\tlearn: 0.0888192\ttotal: 8.94s\tremaining: 20.1s\n",
      "37:\tlearn: 0.0885328\ttotal: 9.17s\tremaining: 19.8s\n",
      "38:\tlearn: 0.0884010\ttotal: 9.41s\tremaining: 19.5s\n",
      "39:\tlearn: 0.0882896\ttotal: 9.63s\tremaining: 19.3s\n",
      "40:\tlearn: 0.0880772\ttotal: 9.85s\tremaining: 19s\n",
      "41:\tlearn: 0.0879441\ttotal: 10.1s\tremaining: 18.7s\n",
      "42:\tlearn: 0.0878090\ttotal: 10.3s\tremaining: 18.4s\n",
      "43:\tlearn: 0.0876702\ttotal: 10.5s\tremaining: 18.2s\n",
      "44:\tlearn: 0.0875251\ttotal: 10.7s\tremaining: 17.9s\n",
      "45:\tlearn: 0.0873194\ttotal: 11s\tremaining: 17.6s\n",
      "46:\tlearn: 0.0871131\ttotal: 11.2s\tremaining: 17.4s\n",
      "47:\tlearn: 0.0870457\ttotal: 11.5s\tremaining: 17.2s\n",
      "48:\tlearn: 0.0869260\ttotal: 11.7s\tremaining: 16.9s\n",
      "49:\tlearn: 0.0867827\ttotal: 11.9s\tremaining: 16.7s\n",
      "50:\tlearn: 0.0866651\ttotal: 12.2s\tremaining: 16.4s\n",
      "51:\tlearn: 0.0865657\ttotal: 12.4s\tremaining: 16.2s\n",
      "52:\tlearn: 0.0864440\ttotal: 12.6s\tremaining: 15.9s\n",
      "53:\tlearn: 0.0863549\ttotal: 12.8s\tremaining: 15.7s\n",
      "54:\tlearn: 0.0862303\ttotal: 13.1s\tremaining: 15.5s\n",
      "55:\tlearn: 0.0860253\ttotal: 13.4s\tremaining: 15.3s\n",
      "56:\tlearn: 0.0858726\ttotal: 13.6s\tremaining: 15s\n",
      "57:\tlearn: 0.0857560\ttotal: 13.8s\tremaining: 14.8s\n",
      "58:\tlearn: 0.0856697\ttotal: 14s\tremaining: 14.5s\n",
      "59:\tlearn: 0.0855562\ttotal: 14.3s\tremaining: 14.3s\n",
      "60:\tlearn: 0.0854392\ttotal: 14.5s\tremaining: 14.1s\n",
      "61:\tlearn: 0.0853049\ttotal: 14.7s\tremaining: 13.8s\n",
      "62:\tlearn: 0.0852553\ttotal: 15s\tremaining: 13.5s\n",
      "63:\tlearn: 0.0851633\ttotal: 15.2s\tremaining: 13.3s\n",
      "64:\tlearn: 0.0850786\ttotal: 15.4s\tremaining: 13s\n",
      "65:\tlearn: 0.0849796\ttotal: 15.6s\tremaining: 12.8s\n",
      "66:\tlearn: 0.0848377\ttotal: 15.9s\tremaining: 12.5s\n",
      "67:\tlearn: 0.0847497\ttotal: 16.1s\tremaining: 12.3s\n",
      "68:\tlearn: 0.0846601\ttotal: 16.3s\tremaining: 12s\n",
      "69:\tlearn: 0.0845661\ttotal: 16.5s\tremaining: 11.8s\n",
      "70:\tlearn: 0.0844461\ttotal: 16.7s\tremaining: 11.5s\n",
      "71:\tlearn: 0.0843637\ttotal: 16.9s\tremaining: 11.3s\n",
      "72:\tlearn: 0.0842883\ttotal: 17.1s\tremaining: 11s\n",
      "73:\tlearn: 0.0842106\ttotal: 17.4s\tremaining: 10.8s\n",
      "74:\tlearn: 0.0841684\ttotal: 17.6s\tremaining: 10.6s\n",
      "75:\tlearn: 0.0841069\ttotal: 17.8s\tremaining: 10.3s\n",
      "76:\tlearn: 0.0840169\ttotal: 18.1s\tremaining: 10.1s\n",
      "77:\tlearn: 0.0839653\ttotal: 18.3s\tremaining: 9.85s\n",
      "78:\tlearn: 0.0839025\ttotal: 18.5s\tremaining: 9.61s\n",
      "79:\tlearn: 0.0838446\ttotal: 18.8s\tremaining: 9.38s\n",
      "80:\tlearn: 0.0837944\ttotal: 19s\tremaining: 9.15s\n",
      "81:\tlearn: 0.0836975\ttotal: 19.2s\tremaining: 8.91s\n",
      "82:\tlearn: 0.0836568\ttotal: 19.5s\tremaining: 8.68s\n",
      "83:\tlearn: 0.0835931\ttotal: 19.7s\tremaining: 8.44s\n",
      "84:\tlearn: 0.0834151\ttotal: 19.9s\tremaining: 8.2s\n",
      "85:\tlearn: 0.0833299\ttotal: 20.1s\tremaining: 7.96s\n",
      "86:\tlearn: 0.0832811\ttotal: 20.4s\tremaining: 7.72s\n",
      "87:\tlearn: 0.0831881\ttotal: 20.6s\tremaining: 7.49s\n",
      "88:\tlearn: 0.0831541\ttotal: 20.8s\tremaining: 7.26s\n",
      "89:\tlearn: 0.0830457\ttotal: 21.1s\tremaining: 7.03s\n",
      "90:\tlearn: 0.0829972\ttotal: 21.3s\tremaining: 6.79s\n",
      "91:\tlearn: 0.0829530\ttotal: 21.6s\tremaining: 6.57s\n",
      "92:\tlearn: 0.0828275\ttotal: 21.8s\tremaining: 6.33s\n",
      "93:\tlearn: 0.0827539\ttotal: 22s\tremaining: 6.1s\n",
      "94:\tlearn: 0.0826548\ttotal: 22.3s\tremaining: 5.87s\n",
      "95:\tlearn: 0.0826050\ttotal: 22.6s\tremaining: 5.64s\n",
      "96:\tlearn: 0.0825682\ttotal: 22.8s\tremaining: 5.41s\n",
      "97:\tlearn: 0.0825280\ttotal: 23s\tremaining: 5.17s\n",
      "98:\tlearn: 0.0825047\ttotal: 23.3s\tremaining: 4.94s\n",
      "99:\tlearn: 0.0824840\ttotal: 23.5s\tremaining: 4.7s\n",
      "100:\tlearn: 0.0824473\ttotal: 23.8s\tremaining: 4.47s\n",
      "101:\tlearn: 0.0824100\ttotal: 24s\tremaining: 4.24s\n",
      "102:\tlearn: 0.0823543\ttotal: 24.3s\tremaining: 4.01s\n",
      "103:\tlearn: 0.0822766\ttotal: 24.5s\tremaining: 3.77s\n",
      "104:\tlearn: 0.0822166\ttotal: 24.8s\tremaining: 3.54s\n",
      "105:\tlearn: 0.0821709\ttotal: 25s\tremaining: 3.3s\n",
      "106:\tlearn: 0.0821403\ttotal: 25.2s\tremaining: 3.06s\n",
      "107:\tlearn: 0.0820868\ttotal: 25.4s\tremaining: 2.83s\n",
      "108:\tlearn: 0.0820034\ttotal: 25.7s\tremaining: 2.59s\n",
      "109:\tlearn: 0.0819445\ttotal: 25.9s\tremaining: 2.36s\n",
      "110:\tlearn: 0.0818866\ttotal: 26.1s\tremaining: 2.12s\n",
      "111:\tlearn: 0.0818309\ttotal: 26.4s\tremaining: 1.88s\n",
      "112:\tlearn: 0.0818060\ttotal: 26.6s\tremaining: 1.65s\n",
      "113:\tlearn: 0.0817631\ttotal: 26.8s\tremaining: 1.41s\n",
      "114:\tlearn: 0.0816858\ttotal: 27.1s\tremaining: 1.18s\n",
      "115:\tlearn: 0.0816623\ttotal: 27.3s\tremaining: 941ms\n",
      "116:\tlearn: 0.0816200\ttotal: 27.5s\tremaining: 706ms\n",
      "117:\tlearn: 0.0815913\ttotal: 27.8s\tremaining: 471ms\n",
      "118:\tlearn: 0.0815547\ttotal: 28s\tremaining: 235ms\n",
      "119:\tlearn: 0.0815249\ttotal: 28.3s\tremaining: 0us\n",
      "0:\tlearn: 0.4836217\ttotal: 235ms\tremaining: 28s\n",
      "1:\tlearn: 0.3341072\ttotal: 475ms\tremaining: 28s\n",
      "2:\tlearn: 0.2696262\ttotal: 696ms\tremaining: 27.1s\n",
      "3:\tlearn: 0.2268214\ttotal: 925ms\tremaining: 26.8s\n",
      "4:\tlearn: 0.1855832\ttotal: 1.17s\tremaining: 26.9s\n",
      "5:\tlearn: 0.1608321\ttotal: 1.41s\tremaining: 26.7s\n",
      "6:\tlearn: 0.1480394\ttotal: 1.61s\tremaining: 26s\n",
      "7:\tlearn: 0.1400355\ttotal: 1.82s\tremaining: 25.5s\n",
      "8:\tlearn: 0.1334170\ttotal: 2.04s\tremaining: 25.1s\n",
      "9:\tlearn: 0.1223694\ttotal: 2.23s\tremaining: 24.5s\n",
      "10:\tlearn: 0.1181975\ttotal: 2.43s\tremaining: 24.1s\n",
      "11:\tlearn: 0.1136322\ttotal: 2.66s\tremaining: 23.9s\n",
      "12:\tlearn: 0.1096830\ttotal: 2.88s\tremaining: 23.7s\n",
      "13:\tlearn: 0.1069403\ttotal: 3.11s\tremaining: 23.5s\n",
      "14:\tlearn: 0.1039458\ttotal: 3.31s\tremaining: 23.2s\n",
      "15:\tlearn: 0.1029415\ttotal: 3.54s\tremaining: 23s\n",
      "16:\tlearn: 0.1008839\ttotal: 3.77s\tremaining: 22.8s\n",
      "17:\tlearn: 0.0991491\ttotal: 4s\tremaining: 22.7s\n",
      "18:\tlearn: 0.0972715\ttotal: 4.25s\tremaining: 22.6s\n",
      "19:\tlearn: 0.0967452\ttotal: 4.47s\tremaining: 22.4s\n",
      "20:\tlearn: 0.0957928\ttotal: 4.72s\tremaining: 22.2s\n",
      "21:\tlearn: 0.0951040\ttotal: 4.94s\tremaining: 22s\n",
      "22:\tlearn: 0.0942897\ttotal: 5.15s\tremaining: 21.7s\n",
      "23:\tlearn: 0.0937210\ttotal: 5.36s\tremaining: 21.5s\n",
      "24:\tlearn: 0.0931695\ttotal: 5.59s\tremaining: 21.3s\n",
      "25:\tlearn: 0.0925439\ttotal: 5.83s\tremaining: 21.1s\n",
      "26:\tlearn: 0.0919899\ttotal: 6.05s\tremaining: 20.8s\n",
      "27:\tlearn: 0.0914777\ttotal: 6.28s\tremaining: 20.6s\n",
      "28:\tlearn: 0.0911653\ttotal: 6.55s\tremaining: 20.5s\n",
      "29:\tlearn: 0.0908896\ttotal: 6.76s\tremaining: 20.3s\n",
      "30:\tlearn: 0.0905032\ttotal: 6.98s\tremaining: 20s\n",
      "31:\tlearn: 0.0902075\ttotal: 7.21s\tremaining: 19.8s\n",
      "32:\tlearn: 0.0898252\ttotal: 7.47s\tremaining: 19.7s\n",
      "33:\tlearn: 0.0895440\ttotal: 7.7s\tremaining: 19.5s\n",
      "34:\tlearn: 0.0892968\ttotal: 7.92s\tremaining: 19.2s\n",
      "35:\tlearn: 0.0890104\ttotal: 8.17s\tremaining: 19.1s\n",
      "36:\tlearn: 0.0886330\ttotal: 8.43s\tremaining: 18.9s\n",
      "37:\tlearn: 0.0883975\ttotal: 8.66s\tremaining: 18.7s\n",
      "38:\tlearn: 0.0882147\ttotal: 8.92s\tremaining: 18.5s\n",
      "39:\tlearn: 0.0880430\ttotal: 9.16s\tremaining: 18.3s\n",
      "40:\tlearn: 0.0878423\ttotal: 9.39s\tremaining: 18.1s\n",
      "41:\tlearn: 0.0876209\ttotal: 9.63s\tremaining: 17.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42:\tlearn: 0.0874182\ttotal: 9.85s\tremaining: 17.6s\n",
      "43:\tlearn: 0.0872687\ttotal: 10.1s\tremaining: 17.4s\n",
      "44:\tlearn: 0.0871654\ttotal: 10.3s\tremaining: 17.2s\n",
      "45:\tlearn: 0.0870214\ttotal: 10.6s\tremaining: 17s\n",
      "46:\tlearn: 0.0868731\ttotal: 10.8s\tremaining: 16.8s\n",
      "47:\tlearn: 0.0867465\ttotal: 11.1s\tremaining: 16.6s\n",
      "48:\tlearn: 0.0865437\ttotal: 11.3s\tremaining: 16.4s\n",
      "49:\tlearn: 0.0863670\ttotal: 11.6s\tremaining: 16.2s\n",
      "50:\tlearn: 0.0862083\ttotal: 11.8s\tremaining: 16s\n",
      "51:\tlearn: 0.0860669\ttotal: 12.1s\tremaining: 15.8s\n",
      "52:\tlearn: 0.0859296\ttotal: 12.3s\tremaining: 15.6s\n",
      "53:\tlearn: 0.0858145\ttotal: 12.5s\tremaining: 15.3s\n",
      "54:\tlearn: 0.0857586\ttotal: 12.8s\tremaining: 15.1s\n",
      "55:\tlearn: 0.0856294\ttotal: 13s\tremaining: 14.8s\n",
      "56:\tlearn: 0.0854637\ttotal: 13.2s\tremaining: 14.6s\n",
      "57:\tlearn: 0.0853681\ttotal: 13.5s\tremaining: 14.4s\n",
      "58:\tlearn: 0.0852892\ttotal: 13.7s\tremaining: 14.1s\n",
      "59:\tlearn: 0.0851315\ttotal: 13.9s\tremaining: 13.9s\n",
      "60:\tlearn: 0.0850506\ttotal: 14.1s\tremaining: 13.7s\n",
      "61:\tlearn: 0.0849362\ttotal: 14.4s\tremaining: 13.4s\n",
      "62:\tlearn: 0.0848516\ttotal: 14.6s\tremaining: 13.2s\n",
      "63:\tlearn: 0.0847947\ttotal: 14.8s\tremaining: 13s\n",
      "64:\tlearn: 0.0847019\ttotal: 15.1s\tremaining: 12.7s\n",
      "65:\tlearn: 0.0846438\ttotal: 15.3s\tremaining: 12.5s\n",
      "66:\tlearn: 0.0845475\ttotal: 15.5s\tremaining: 12.3s\n",
      "67:\tlearn: 0.0844021\ttotal: 15.8s\tremaining: 12s\n",
      "68:\tlearn: 0.0843533\ttotal: 16s\tremaining: 11.8s\n",
      "69:\tlearn: 0.0841918\ttotal: 16.2s\tremaining: 11.6s\n",
      "70:\tlearn: 0.0841157\ttotal: 16.4s\tremaining: 11.3s\n",
      "71:\tlearn: 0.0840447\ttotal: 16.6s\tremaining: 11.1s\n",
      "72:\tlearn: 0.0839710\ttotal: 16.9s\tremaining: 10.9s\n",
      "73:\tlearn: 0.0839040\ttotal: 17.1s\tremaining: 10.6s\n",
      "74:\tlearn: 0.0838571\ttotal: 17.3s\tremaining: 10.4s\n",
      "75:\tlearn: 0.0837671\ttotal: 17.6s\tremaining: 10.2s\n",
      "76:\tlearn: 0.0835839\ttotal: 17.8s\tremaining: 9.96s\n",
      "77:\tlearn: 0.0835092\ttotal: 18.1s\tremaining: 9.73s\n",
      "78:\tlearn: 0.0834497\ttotal: 18.3s\tremaining: 9.49s\n",
      "79:\tlearn: 0.0834047\ttotal: 18.5s\tremaining: 9.25s\n",
      "80:\tlearn: 0.0832384\ttotal: 18.7s\tremaining: 9.02s\n",
      "81:\tlearn: 0.0831987\ttotal: 19s\tremaining: 8.78s\n",
      "82:\tlearn: 0.0831398\ttotal: 19.2s\tremaining: 8.54s\n",
      "83:\tlearn: 0.0830774\ttotal: 19.4s\tremaining: 8.31s\n",
      "84:\tlearn: 0.0829758\ttotal: 19.6s\tremaining: 8.07s\n",
      "85:\tlearn: 0.0828475\ttotal: 19.8s\tremaining: 7.85s\n",
      "86:\tlearn: 0.0828138\ttotal: 20.1s\tremaining: 7.61s\n",
      "87:\tlearn: 0.0827112\ttotal: 20.3s\tremaining: 7.38s\n",
      "88:\tlearn: 0.0826131\ttotal: 20.5s\tremaining: 7.14s\n",
      "89:\tlearn: 0.0825349\ttotal: 20.8s\tremaining: 6.92s\n",
      "90:\tlearn: 0.0824938\ttotal: 21s\tremaining: 6.69s\n",
      "91:\tlearn: 0.0824027\ttotal: 21.2s\tremaining: 6.46s\n",
      "92:\tlearn: 0.0823269\ttotal: 21.5s\tremaining: 6.24s\n",
      "93:\tlearn: 0.0822785\ttotal: 21.7s\tremaining: 6.01s\n",
      "94:\tlearn: 0.0822533\ttotal: 21.9s\tremaining: 5.77s\n",
      "95:\tlearn: 0.0821967\ttotal: 22.1s\tremaining: 5.54s\n",
      "96:\tlearn: 0.0821677\ttotal: 22.4s\tremaining: 5.31s\n",
      "97:\tlearn: 0.0821242\ttotal: 22.6s\tremaining: 5.08s\n",
      "98:\tlearn: 0.0820937\ttotal: 22.8s\tremaining: 4.84s\n",
      "99:\tlearn: 0.0819971\ttotal: 23.1s\tremaining: 4.61s\n",
      "100:\tlearn: 0.0819734\ttotal: 23.3s\tremaining: 4.38s\n",
      "101:\tlearn: 0.0818728\ttotal: 23.5s\tremaining: 4.15s\n",
      "102:\tlearn: 0.0818401\ttotal: 23.7s\tremaining: 3.92s\n",
      "103:\tlearn: 0.0817942\ttotal: 24s\tremaining: 3.69s\n",
      "104:\tlearn: 0.0817587\ttotal: 24.2s\tremaining: 3.46s\n",
      "105:\tlearn: 0.0816949\ttotal: 24.4s\tremaining: 3.23s\n",
      "106:\tlearn: 0.0816540\ttotal: 24.7s\tremaining: 3s\n",
      "107:\tlearn: 0.0816021\ttotal: 24.9s\tremaining: 2.77s\n",
      "108:\tlearn: 0.0815719\ttotal: 25.1s\tremaining: 2.54s\n",
      "109:\tlearn: 0.0815481\ttotal: 25.4s\tremaining: 2.31s\n",
      "110:\tlearn: 0.0814975\ttotal: 25.6s\tremaining: 2.08s\n",
      "111:\tlearn: 0.0814418\ttotal: 25.8s\tremaining: 1.84s\n",
      "112:\tlearn: 0.0814018\ttotal: 26.1s\tremaining: 1.61s\n",
      "113:\tlearn: 0.0813645\ttotal: 26.3s\tremaining: 1.38s\n",
      "114:\tlearn: 0.0813242\ttotal: 26.5s\tremaining: 1.15s\n",
      "115:\tlearn: 0.0812810\ttotal: 26.8s\tremaining: 924ms\n",
      "116:\tlearn: 0.0812523\ttotal: 27s\tremaining: 693ms\n",
      "117:\tlearn: 0.0811979\ttotal: 27.3s\tremaining: 463ms\n",
      "118:\tlearn: 0.0811645\ttotal: 27.5s\tremaining: 231ms\n",
      "119:\tlearn: 0.0811316\ttotal: 27.7s\tremaining: 0us\n",
      "0:\tlearn: 0.4795459\ttotal: 243ms\tremaining: 28.9s\n",
      "1:\tlearn: 0.3796904\ttotal: 465ms\tremaining: 27.5s\n",
      "2:\tlearn: 0.2847949\ttotal: 703ms\tremaining: 27.4s\n",
      "3:\tlearn: 0.2308494\ttotal: 930ms\tremaining: 27s\n",
      "4:\tlearn: 0.1984943\ttotal: 1.15s\tremaining: 26.5s\n",
      "5:\tlearn: 0.1634730\ttotal: 1.42s\tremaining: 26.9s\n",
      "6:\tlearn: 0.1507900\ttotal: 1.63s\tremaining: 26.2s\n",
      "7:\tlearn: 0.1367410\ttotal: 1.84s\tremaining: 25.7s\n",
      "8:\tlearn: 0.1262627\ttotal: 2.07s\tremaining: 25.6s\n",
      "9:\tlearn: 0.1223862\ttotal: 2.31s\tremaining: 25.4s\n",
      "10:\tlearn: 0.1172021\ttotal: 2.56s\tremaining: 25.4s\n",
      "11:\tlearn: 0.1147770\ttotal: 2.81s\tremaining: 25.3s\n",
      "12:\tlearn: 0.1102801\ttotal: 3.07s\tremaining: 25.2s\n",
      "13:\tlearn: 0.1065243\ttotal: 3.3s\tremaining: 25s\n",
      "14:\tlearn: 0.1035179\ttotal: 3.55s\tremaining: 24.8s\n",
      "15:\tlearn: 0.1014309\ttotal: 3.79s\tremaining: 24.7s\n",
      "16:\tlearn: 0.0999208\ttotal: 4.03s\tremaining: 24.4s\n",
      "17:\tlearn: 0.0984761\ttotal: 4.25s\tremaining: 24.1s\n",
      "18:\tlearn: 0.0972340\ttotal: 4.52s\tremaining: 24s\n",
      "19:\tlearn: 0.0958619\ttotal: 4.76s\tremaining: 23.8s\n",
      "20:\tlearn: 0.0951597\ttotal: 4.99s\tremaining: 23.5s\n",
      "21:\tlearn: 0.0944913\ttotal: 5.27s\tremaining: 23.5s\n",
      "22:\tlearn: 0.0938341\ttotal: 5.5s\tremaining: 23.2s\n",
      "23:\tlearn: 0.0933564\ttotal: 5.73s\tremaining: 22.9s\n",
      "24:\tlearn: 0.0928015\ttotal: 5.97s\tremaining: 22.7s\n",
      "25:\tlearn: 0.0923592\ttotal: 6.21s\tremaining: 22.5s\n",
      "26:\tlearn: 0.0919073\ttotal: 6.45s\tremaining: 22.2s\n",
      "27:\tlearn: 0.0916421\ttotal: 6.67s\tremaining: 21.9s\n",
      "28:\tlearn: 0.0912412\ttotal: 6.9s\tremaining: 21.6s\n",
      "29:\tlearn: 0.0910149\ttotal: 7.1s\tremaining: 21.3s\n",
      "30:\tlearn: 0.0906621\ttotal: 7.32s\tremaining: 21s\n",
      "31:\tlearn: 0.0903410\ttotal: 7.59s\tremaining: 20.9s\n",
      "32:\tlearn: 0.0900308\ttotal: 7.82s\tremaining: 20.6s\n",
      "33:\tlearn: 0.0898416\ttotal: 8.05s\tremaining: 20.4s\n",
      "34:\tlearn: 0.0895904\ttotal: 8.29s\tremaining: 20.1s\n",
      "35:\tlearn: 0.0892988\ttotal: 8.52s\tremaining: 19.9s\n",
      "36:\tlearn: 0.0889667\ttotal: 8.75s\tremaining: 19.6s\n",
      "37:\tlearn: 0.0887129\ttotal: 8.99s\tremaining: 19.4s\n",
      "38:\tlearn: 0.0884906\ttotal: 9.21s\tremaining: 19.1s\n",
      "39:\tlearn: 0.0883208\ttotal: 9.44s\tremaining: 18.9s\n",
      "40:\tlearn: 0.0881687\ttotal: 9.69s\tremaining: 18.7s\n",
      "41:\tlearn: 0.0879477\ttotal: 9.95s\tremaining: 18.5s\n",
      "42:\tlearn: 0.0877565\ttotal: 10.2s\tremaining: 18.2s\n",
      "43:\tlearn: 0.0876607\ttotal: 10.4s\tremaining: 17.9s\n",
      "44:\tlearn: 0.0874915\ttotal: 10.6s\tremaining: 17.6s\n",
      "45:\tlearn: 0.0870846\ttotal: 10.8s\tremaining: 17.4s\n",
      "46:\tlearn: 0.0869383\ttotal: 11.1s\tremaining: 17.2s\n",
      "47:\tlearn: 0.0868354\ttotal: 11.3s\tremaining: 17s\n",
      "48:\tlearn: 0.0867550\ttotal: 11.6s\tremaining: 16.8s\n",
      "49:\tlearn: 0.0866265\ttotal: 11.8s\tremaining: 16.5s\n",
      "50:\tlearn: 0.0865279\ttotal: 12s\tremaining: 16.3s\n",
      "51:\tlearn: 0.0863244\ttotal: 12.3s\tremaining: 16.1s\n",
      "52:\tlearn: 0.0862104\ttotal: 12.6s\tremaining: 15.9s\n",
      "53:\tlearn: 0.0860512\ttotal: 12.8s\tremaining: 15.6s\n",
      "54:\tlearn: 0.0859490\ttotal: 13s\tremaining: 15.4s\n",
      "55:\tlearn: 0.0858251\ttotal: 13.3s\tremaining: 15.2s\n",
      "56:\tlearn: 0.0857358\ttotal: 13.5s\tremaining: 15s\n",
      "57:\tlearn: 0.0856473\ttotal: 13.7s\tremaining: 14.7s\n",
      "58:\tlearn: 0.0855754\ttotal: 14s\tremaining: 14.4s\n",
      "59:\tlearn: 0.0854804\ttotal: 14.2s\tremaining: 14.2s\n",
      "60:\tlearn: 0.0853619\ttotal: 14.5s\tremaining: 14s\n",
      "61:\tlearn: 0.0853205\ttotal: 14.7s\tremaining: 13.8s\n",
      "62:\tlearn: 0.0852326\ttotal: 15s\tremaining: 13.6s\n",
      "63:\tlearn: 0.0851650\ttotal: 15.2s\tremaining: 13.3s\n",
      "64:\tlearn: 0.0849958\ttotal: 15.5s\tremaining: 13.1s\n",
      "65:\tlearn: 0.0849192\ttotal: 15.7s\tremaining: 12.9s\n",
      "66:\tlearn: 0.0848654\ttotal: 16s\tremaining: 12.7s\n",
      "67:\tlearn: 0.0847758\ttotal: 16.2s\tremaining: 12.4s\n",
      "68:\tlearn: 0.0846384\ttotal: 16.4s\tremaining: 12.2s\n",
      "69:\tlearn: 0.0845688\ttotal: 16.7s\tremaining: 11.9s\n",
      "70:\tlearn: 0.0845148\ttotal: 16.9s\tremaining: 11.7s\n",
      "71:\tlearn: 0.0844320\ttotal: 17.2s\tremaining: 11.4s\n",
      "72:\tlearn: 0.0842842\ttotal: 17.4s\tremaining: 11.2s\n",
      "73:\tlearn: 0.0842222\ttotal: 17.7s\tremaining: 11s\n",
      "74:\tlearn: 0.0841572\ttotal: 17.9s\tremaining: 10.7s\n",
      "75:\tlearn: 0.0840896\ttotal: 18.2s\tremaining: 10.5s\n",
      "76:\tlearn: 0.0840462\ttotal: 18.4s\tremaining: 10.3s\n",
      "77:\tlearn: 0.0839987\ttotal: 18.6s\tremaining: 10s\n",
      "78:\tlearn: 0.0839442\ttotal: 18.9s\tremaining: 9.79s\n",
      "79:\tlearn: 0.0839074\ttotal: 19.1s\tremaining: 9.55s\n",
      "80:\tlearn: 0.0838685\ttotal: 19.4s\tremaining: 9.32s\n",
      "81:\tlearn: 0.0838420\ttotal: 19.6s\tremaining: 9.08s\n",
      "82:\tlearn: 0.0837763\ttotal: 19.8s\tremaining: 8.83s\n",
      "83:\tlearn: 0.0836993\ttotal: 20.1s\tremaining: 8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84:\tlearn: 0.0836279\ttotal: 20.3s\tremaining: 8.36s\n",
      "85:\tlearn: 0.0835712\ttotal: 20.6s\tremaining: 8.13s\n",
      "86:\tlearn: 0.0834576\ttotal: 20.8s\tremaining: 7.9s\n",
      "87:\tlearn: 0.0833907\ttotal: 21.1s\tremaining: 7.67s\n",
      "88:\tlearn: 0.0833480\ttotal: 21.3s\tremaining: 7.42s\n",
      "89:\tlearn: 0.0832494\ttotal: 21.6s\tremaining: 7.19s\n",
      "90:\tlearn: 0.0832043\ttotal: 21.8s\tremaining: 6.96s\n",
      "91:\tlearn: 0.0831742\ttotal: 22.1s\tremaining: 6.71s\n",
      "92:\tlearn: 0.0831035\ttotal: 22.3s\tremaining: 6.48s\n",
      "93:\tlearn: 0.0830356\ttotal: 22.6s\tremaining: 6.26s\n",
      "94:\tlearn: 0.0828521\ttotal: 22.9s\tremaining: 6.03s\n",
      "95:\tlearn: 0.0827264\ttotal: 23.2s\tremaining: 5.8s\n",
      "96:\tlearn: 0.0826292\ttotal: 23.4s\tremaining: 5.55s\n",
      "97:\tlearn: 0.0825618\ttotal: 23.7s\tremaining: 5.31s\n",
      "98:\tlearn: 0.0825270\ttotal: 23.9s\tremaining: 5.07s\n",
      "99:\tlearn: 0.0824839\ttotal: 24.2s\tremaining: 4.83s\n",
      "100:\tlearn: 0.0824365\ttotal: 24.4s\tremaining: 4.59s\n",
      "101:\tlearn: 0.0824107\ttotal: 24.6s\tremaining: 4.34s\n",
      "102:\tlearn: 0.0823692\ttotal: 24.8s\tremaining: 4.09s\n",
      "103:\tlearn: 0.0823542\ttotal: 25s\tremaining: 3.85s\n",
      "104:\tlearn: 0.0823101\ttotal: 25.3s\tremaining: 3.61s\n",
      "105:\tlearn: 0.0822891\ttotal: 25.5s\tremaining: 3.36s\n",
      "106:\tlearn: 0.0822302\ttotal: 25.7s\tremaining: 3.12s\n",
      "107:\tlearn: 0.0821447\ttotal: 25.9s\tremaining: 2.88s\n",
      "108:\tlearn: 0.0820817\ttotal: 26.2s\tremaining: 2.64s\n",
      "109:\tlearn: 0.0820388\ttotal: 26.4s\tremaining: 2.4s\n",
      "110:\tlearn: 0.0819412\ttotal: 26.6s\tremaining: 2.16s\n",
      "111:\tlearn: 0.0818702\ttotal: 26.9s\tremaining: 1.92s\n",
      "112:\tlearn: 0.0818369\ttotal: 27.1s\tremaining: 1.68s\n",
      "113:\tlearn: 0.0818143\ttotal: 27.4s\tremaining: 1.44s\n",
      "114:\tlearn: 0.0817484\ttotal: 27.6s\tremaining: 1.2s\n",
      "115:\tlearn: 0.0817017\ttotal: 27.9s\tremaining: 961ms\n",
      "116:\tlearn: 0.0816849\ttotal: 28.1s\tremaining: 720ms\n",
      "117:\tlearn: 0.0816514\ttotal: 28.3s\tremaining: 480ms\n",
      "118:\tlearn: 0.0816196\ttotal: 28.5s\tremaining: 240ms\n",
      "119:\tlearn: 0.0815761\ttotal: 28.8s\tremaining: 0us\n",
      "0:\tlearn: 0.4796919\ttotal: 242ms\tremaining: 28.8s\n",
      "1:\tlearn: 0.3797408\ttotal: 471ms\tremaining: 27.8s\n",
      "2:\tlearn: 0.2846314\ttotal: 676ms\tremaining: 26.4s\n",
      "3:\tlearn: 0.2181623\ttotal: 902ms\tremaining: 26.2s\n",
      "4:\tlearn: 0.1887802\ttotal: 1.12s\tremaining: 25.7s\n",
      "5:\tlearn: 0.1572767\ttotal: 1.34s\tremaining: 25.5s\n",
      "6:\tlearn: 0.1457347\ttotal: 1.54s\tremaining: 24.9s\n",
      "7:\tlearn: 0.1361553\ttotal: 1.8s\tremaining: 25.2s\n",
      "8:\tlearn: 0.1276637\ttotal: 2.03s\tremaining: 25.1s\n",
      "9:\tlearn: 0.1236820\ttotal: 2.3s\tremaining: 25.3s\n",
      "10:\tlearn: 0.1203123\ttotal: 2.52s\tremaining: 25s\n",
      "11:\tlearn: 0.1156333\ttotal: 2.72s\tremaining: 24.5s\n",
      "12:\tlearn: 0.1098876\ttotal: 2.96s\tremaining: 24.4s\n",
      "13:\tlearn: 0.1060578\ttotal: 3.2s\tremaining: 24.3s\n",
      "14:\tlearn: 0.1033129\ttotal: 3.41s\tremaining: 23.9s\n",
      "15:\tlearn: 0.1016628\ttotal: 3.6s\tremaining: 23.4s\n",
      "16:\tlearn: 0.1003291\ttotal: 3.83s\tremaining: 23.2s\n",
      "17:\tlearn: 0.0987349\ttotal: 4.07s\tremaining: 23.1s\n",
      "18:\tlearn: 0.0970224\ttotal: 4.33s\tremaining: 23s\n",
      "19:\tlearn: 0.0963216\ttotal: 4.55s\tremaining: 22.8s\n",
      "20:\tlearn: 0.0952855\ttotal: 4.76s\tremaining: 22.5s\n",
      "21:\tlearn: 0.0944049\ttotal: 5.06s\tremaining: 22.5s\n",
      "22:\tlearn: 0.0937104\ttotal: 5.3s\tremaining: 22.4s\n",
      "23:\tlearn: 0.0932342\ttotal: 5.54s\tremaining: 22.2s\n",
      "24:\tlearn: 0.0928044\ttotal: 5.77s\tremaining: 21.9s\n",
      "25:\tlearn: 0.0924141\ttotal: 6.02s\tremaining: 21.8s\n",
      "26:\tlearn: 0.0921150\ttotal: 6.25s\tremaining: 21.5s\n",
      "27:\tlearn: 0.0916818\ttotal: 6.51s\tremaining: 21.4s\n",
      "28:\tlearn: 0.0912063\ttotal: 6.74s\tremaining: 21.2s\n",
      "29:\tlearn: 0.0908269\ttotal: 6.94s\tremaining: 20.8s\n",
      "30:\tlearn: 0.0905747\ttotal: 7.16s\tremaining: 20.6s\n",
      "31:\tlearn: 0.0902607\ttotal: 7.39s\tremaining: 20.3s\n",
      "32:\tlearn: 0.0899958\ttotal: 7.63s\tremaining: 20.1s\n",
      "33:\tlearn: 0.0896569\ttotal: 7.88s\tremaining: 19.9s\n",
      "34:\tlearn: 0.0894093\ttotal: 8.11s\tremaining: 19.7s\n",
      "35:\tlearn: 0.0892518\ttotal: 8.31s\tremaining: 19.4s\n",
      "36:\tlearn: 0.0890397\ttotal: 8.53s\tremaining: 19.1s\n",
      "37:\tlearn: 0.0888301\ttotal: 8.76s\tremaining: 18.9s\n",
      "38:\tlearn: 0.0886254\ttotal: 8.98s\tremaining: 18.6s\n",
      "39:\tlearn: 0.0884512\ttotal: 9.24s\tremaining: 18.5s\n",
      "40:\tlearn: 0.0882502\ttotal: 9.47s\tremaining: 18.2s\n",
      "41:\tlearn: 0.0880724\ttotal: 9.7s\tremaining: 18s\n",
      "42:\tlearn: 0.0879548\ttotal: 9.95s\tremaining: 17.8s\n",
      "43:\tlearn: 0.0877793\ttotal: 10.2s\tremaining: 17.6s\n",
      "44:\tlearn: 0.0876088\ttotal: 10.5s\tremaining: 17.4s\n",
      "45:\tlearn: 0.0874755\ttotal: 10.7s\tremaining: 17.2s\n",
      "46:\tlearn: 0.0873491\ttotal: 10.9s\tremaining: 17s\n",
      "47:\tlearn: 0.0871923\ttotal: 11.2s\tremaining: 16.8s\n",
      "48:\tlearn: 0.0870314\ttotal: 11.4s\tremaining: 16.6s\n",
      "49:\tlearn: 0.0869511\ttotal: 11.7s\tremaining: 16.4s\n",
      "50:\tlearn: 0.0868288\ttotal: 12s\tremaining: 16.2s\n",
      "51:\tlearn: 0.0866504\ttotal: 12.2s\tremaining: 15.9s\n",
      "52:\tlearn: 0.0865365\ttotal: 12.4s\tremaining: 15.7s\n",
      "53:\tlearn: 0.0862388\ttotal: 12.7s\tremaining: 15.5s\n",
      "54:\tlearn: 0.0861068\ttotal: 12.9s\tremaining: 15.3s\n",
      "55:\tlearn: 0.0859014\ttotal: 13.2s\tremaining: 15.1s\n",
      "56:\tlearn: 0.0858347\ttotal: 13.5s\tremaining: 14.9s\n",
      "57:\tlearn: 0.0857321\ttotal: 13.7s\tremaining: 14.6s\n",
      "58:\tlearn: 0.0856189\ttotal: 13.9s\tremaining: 14.4s\n",
      "59:\tlearn: 0.0855101\ttotal: 14.2s\tremaining: 14.2s\n",
      "60:\tlearn: 0.0853980\ttotal: 14.4s\tremaining: 13.9s\n",
      "61:\tlearn: 0.0852937\ttotal: 14.7s\tremaining: 13.7s\n",
      "62:\tlearn: 0.0852018\ttotal: 14.9s\tremaining: 13.5s\n",
      "63:\tlearn: 0.0851395\ttotal: 15.1s\tremaining: 13.2s\n",
      "64:\tlearn: 0.0850455\ttotal: 15.3s\tremaining: 13s\n",
      "65:\tlearn: 0.0849204\ttotal: 15.6s\tremaining: 12.7s\n",
      "66:\tlearn: 0.0848346\ttotal: 15.8s\tremaining: 12.5s\n",
      "67:\tlearn: 0.0847744\ttotal: 16s\tremaining: 12.2s\n",
      "68:\tlearn: 0.0846950\ttotal: 16.2s\tremaining: 12s\n",
      "69:\tlearn: 0.0846431\ttotal: 16.5s\tremaining: 11.8s\n",
      "70:\tlearn: 0.0845930\ttotal: 16.7s\tremaining: 11.5s\n",
      "71:\tlearn: 0.0845609\ttotal: 17s\tremaining: 11.3s\n",
      "72:\tlearn: 0.0844976\ttotal: 17.2s\tremaining: 11.1s\n",
      "73:\tlearn: 0.0844170\ttotal: 17.4s\tremaining: 10.8s\n",
      "74:\tlearn: 0.0843436\ttotal: 17.6s\tremaining: 10.6s\n",
      "75:\tlearn: 0.0842764\ttotal: 17.9s\tremaining: 10.4s\n",
      "76:\tlearn: 0.0842038\ttotal: 18.1s\tremaining: 10.1s\n",
      "77:\tlearn: 0.0841255\ttotal: 18.4s\tremaining: 9.89s\n",
      "78:\tlearn: 0.0840475\ttotal: 18.6s\tremaining: 9.65s\n",
      "79:\tlearn: 0.0839859\ttotal: 18.8s\tremaining: 9.41s\n",
      "80:\tlearn: 0.0838601\ttotal: 19.1s\tremaining: 9.18s\n",
      "81:\tlearn: 0.0838068\ttotal: 19.3s\tremaining: 8.96s\n",
      "82:\tlearn: 0.0837644\ttotal: 19.6s\tremaining: 8.72s\n",
      "83:\tlearn: 0.0837090\ttotal: 19.8s\tremaining: 8.49s\n",
      "84:\tlearn: 0.0836511\ttotal: 20.1s\tremaining: 8.27s\n",
      "85:\tlearn: 0.0835737\ttotal: 20.3s\tremaining: 8.03s\n",
      "86:\tlearn: 0.0835084\ttotal: 20.5s\tremaining: 7.79s\n",
      "87:\tlearn: 0.0834634\ttotal: 20.8s\tremaining: 7.58s\n",
      "88:\tlearn: 0.0832889\ttotal: 21.1s\tremaining: 7.34s\n",
      "89:\tlearn: 0.0832487\ttotal: 21.3s\tremaining: 7.1s\n",
      "90:\tlearn: 0.0832059\ttotal: 21.5s\tremaining: 6.85s\n",
      "91:\tlearn: 0.0831017\ttotal: 21.7s\tremaining: 6.61s\n",
      "92:\tlearn: 0.0830740\ttotal: 21.9s\tremaining: 6.37s\n",
      "93:\tlearn: 0.0830176\ttotal: 22.2s\tremaining: 6.14s\n",
      "94:\tlearn: 0.0829869\ttotal: 22.4s\tremaining: 5.9s\n",
      "95:\tlearn: 0.0829095\ttotal: 22.7s\tremaining: 5.67s\n",
      "96:\tlearn: 0.0828414\ttotal: 22.9s\tremaining: 5.43s\n",
      "97:\tlearn: 0.0828008\ttotal: 23.1s\tremaining: 5.19s\n",
      "98:\tlearn: 0.0827351\ttotal: 23.4s\tremaining: 4.96s\n",
      "99:\tlearn: 0.0827054\ttotal: 23.6s\tremaining: 4.72s\n",
      "100:\tlearn: 0.0826682\ttotal: 23.8s\tremaining: 4.49s\n",
      "101:\tlearn: 0.0826075\ttotal: 24.1s\tremaining: 4.25s\n",
      "102:\tlearn: 0.0825573\ttotal: 24.3s\tremaining: 4.02s\n",
      "103:\tlearn: 0.0825028\ttotal: 24.6s\tremaining: 3.78s\n",
      "104:\tlearn: 0.0824469\ttotal: 24.8s\tremaining: 3.54s\n",
      "105:\tlearn: 0.0824105\ttotal: 25s\tremaining: 3.31s\n",
      "106:\tlearn: 0.0823947\ttotal: 25.3s\tremaining: 3.07s\n",
      "107:\tlearn: 0.0823482\ttotal: 25.5s\tremaining: 2.83s\n",
      "108:\tlearn: 0.0822266\ttotal: 25.8s\tremaining: 2.6s\n",
      "109:\tlearn: 0.0821298\ttotal: 26s\tremaining: 2.37s\n",
      "110:\tlearn: 0.0820800\ttotal: 26.3s\tremaining: 2.13s\n",
      "111:\tlearn: 0.0820093\ttotal: 26.5s\tremaining: 1.89s\n",
      "112:\tlearn: 0.0819780\ttotal: 26.7s\tremaining: 1.66s\n",
      "113:\tlearn: 0.0819328\ttotal: 27s\tremaining: 1.42s\n",
      "114:\tlearn: 0.0819047\ttotal: 27.2s\tremaining: 1.18s\n",
      "115:\tlearn: 0.0818642\ttotal: 27.4s\tremaining: 946ms\n",
      "116:\tlearn: 0.0818136\ttotal: 27.7s\tremaining: 710ms\n",
      "117:\tlearn: 0.0817742\ttotal: 27.9s\tremaining: 473ms\n",
      "118:\tlearn: 0.0817554\ttotal: 28.1s\tremaining: 236ms\n",
      "119:\tlearn: 0.0817259\ttotal: 28.4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Catboost\n",
    "model = CatBoostClassifier(iterations=120, learning_rate=0.1, loss_function='CrossEntropy', \n",
    "                        custom_loss = 'Logloss', random_seed = 167, l2_leaf_reg=3, bagging_temperature=1, random_strength=1, \n",
    "                        one_hot_max_size=2, leaf_estimation_method='Newton')\n",
    "cb = features_stacking(X, Y, X_test, model, cv = 4, name_model_as_feature = 'cb', random_state = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model = XGBClassifier(learning_rate = 0.1, n_estimators = 150, max_depth=5, min_child_weight=5, gamma=0, subsample=0.8,\n",
    "                      colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "xgb = features_stacking(X, Y, X_test, model, cv = 4, name_model_as_feature = 'xgb', random_state = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "model = MLPClassifier(hidden_layer_sizes = (50, 100, 80), alpha = 0.001, batch_size = 128, max_iter = 10)\n",
    "nn = features_stacking(X, Y, X_test, model, cv = 4, name_model_as_feature = 'nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train = pd.concat([randomforest[0], cb[0], xgb[0], nn[0]], axis = 1)\n",
    "stacking_test = pd.concat([randomforest[1], cb[1], xgb[1], nn[1]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda3\\envs\\THANGHOANG\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(stacking_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09259864825435275"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y, clf.predict_proba(stacking_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3691638522667676"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y_test, clf.predict_proba(stacking_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_stacked = clf.predict_proba(stacking_test)\n",
    "submission = pd.DataFrame({'msno': test['msno'], 'is_churn': Y_test_stacked[:, 1].ravel()})\n",
    "submission.to_csv('stack1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators = 150,\n",
    " max_depth=5,\n",
    " min_child_weight=5,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.664264\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "[50]\tvalidation_0-logloss:0.551337\n",
      "[100]\tvalidation_0-logloss:0.54494\n",
      "Stopping. Best iteration:\n",
      "[96]\tvalidation_0-logloss:0.543352\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=5, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(stacking_train, Y, eval_metric = 'logloss', eval_set = [(stacking_test, Y_test)], early_stopping_rounds = 50, verbose = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4226236\ttest: 0.6691899\tbest: 0.6691899 (0)\ttotal: 289ms\tremaining: 43.1s\n",
      "50:\tlearn: 0.0792276\ttest: 0.5337726\tbest: 0.5325972 (32)\ttotal: 14s\tremaining: 27.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.5325971841\n",
      "bestIteration = 32\n",
      "\n",
      "Shrink model to first 33 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d1011e4128>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb1 = CatBoostClassifier(iterations=150, learning_rate=0.1, od_type='Iter', od_wait=50, loss_function='CrossEntropy', \n",
    "                        custom_loss = 'Logloss', random_seed = 167, l2_leaf_reg=3, bagging_temperature=1, random_strength=1, \n",
    "                        one_hot_max_size=2, leaf_estimation_method='Newton')\n",
    "cb1.fit(stacking_train, Y, eval_set=(stacking_test, Y_test), verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv('submission_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Van Anh</td>\n",
       "      <td>19-Jan</td>\n",
       "      <td>0.17540</td>\n",
       "      <td>Catboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Van Anh</td>\n",
       "      <td>21-Jan</td>\n",
       "      <td>0.16270</td>\n",
       "      <td>Catboost ( Members and Transactions features)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datcm</td>\n",
       "      <td>22-Jan</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>Catboost (Members and userlogs features)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Van Anh</td>\n",
       "      <td>25-Jan</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>Catboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Van Anh</td>\n",
       "      <td>26-Jan</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>Catboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thang Hoang</td>\n",
       "      <td>8-Feb</td>\n",
       "      <td>0.12747</td>\n",
       "      <td>XGBoost (Members, Transactions and user_logs f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name    Date   Best Score  \\\n",
       "0      Van Anh  19-Jan      0.17540   \n",
       "1      Van Anh  21-Jan      0.16270   \n",
       "2        Datcm  22-Jan      1.20000   \n",
       "3      Van Anh  25-Jan      0.11990   \n",
       "4      Van Anh  26-Jan      0.11700   \n",
       "5  Thang Hoang   8-Feb      0.12747   \n",
       "\n",
       "                                             Comment  \n",
       "0                                           Catboost  \n",
       "1      Catboost ( Members and Transactions features)  \n",
       "2           Catboost (Members and userlogs features)  \n",
       "3                                           Catboost  \n",
       "4                                           Catboost  \n",
       "5  XGBoost (Members, Transactions and user_logs f...  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score.iloc[:5, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      "Name           5 non-null object\n",
      " Date          5 non-null object\n",
      " Best Score    5 non-null float64\n",
      " Comment       5 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 240.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score.append({'Name': 'Thang Hoang',\n",
    "              ' Date': '8-Feb', \n",
    "              ' Best Score': 0.12747, \n",
    "              ' Comment': 'XGBoost (Members, Transactions and user_logs features)'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_csv('submission_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THANGHOANG",
   "language": "python",
   "name": "thanghoang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
